{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "\n",
    "# check version\n",
    "pytorch_lightning.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1+cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# check version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# load iris dataset\n",
    "x, t = load_iris(return_X_y=True)\n",
    "\n",
    "# transform to the format for learning with PyTorch\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "t = torch.tensor(t, dtype=torch.int64)\n",
    "\n",
    "# transform input value and target value together to a object \"dataset\"\n",
    "dataset = TensorDataset(x, t)\n",
    "\n",
    "# set sample num of each dataset\n",
    "# train : val : test = 60% : 20% : 20%\n",
    "n_train = int(len(dataset) * 0.6)\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "\n",
    "# because of random split, fix random number seed to maintain reproductivity\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# split dataset\n",
    "train, val, test = random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# definition of batch size\n",
    "batch_size = 32\n",
    "\n",
    "# preparing DataLoader\n",
    "# shuffle is False in default, so only train dataset is set True\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(4)\n",
    "        self.fc1 = nn.Linear(4, 4)\n",
    "        self.fc2 = nn.Linear(4, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.bn(x)\n",
    "        h = self.fc1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.fc2(h)\n",
    "        return h\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, t = batch\n",
    "        y = self(x)\n",
    "        loss = F.cross_entropy(y, t)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type        | Params\n",
      "-------------------------------------\n",
      "0 | bn   | BatchNorm1d | 8     \n",
      "1 | fc1  | Linear      | 20    \n",
      "2 | fc2  | Linear      | 15    \n",
      "-------------------------------------\n",
      "43        Trainable params\n",
      "0         Non-trainable params\n",
      "43        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2/2 [00:00<00:00, 50.09it/s, loss=1.04, v_num=2] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2/2 [00:00<00:00, 36.70it/s, loss=1.04, v_num=2]\n"
     ]
    }
   ],
   "source": [
    "# fix random number seed including GPU\n",
    "pl.seed_everything(0)\n",
    "net = Net()\n",
    "\n",
    "# definition of trainer\n",
    "trainer = pl.Trainer(max_epochs=5)\n",
    "\n",
    "# learning\n",
    "trainer.fit(net, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorboard\n",
    "\n",
    "tensorboard.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(4)\n",
    "        self.fc1 = nn.Linear(4, 4)\n",
    "        self.fc2 = nn.Linear(4, 3)\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.bn(x)\n",
    "        h = self.fc1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.fc2(h)\n",
    "        return h\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, t = batch\n",
    "        y = self(x)\n",
    "        loss = F.cross_entropy(y, t)\n",
    "        # add log\n",
    "        # if on_step==True, the value of each iteration is recorded(default: True)\n",
    "        # if on_epoch==True, the value of each epoch is recorded(default: False)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.log('train_acc', self.train_acc(y, t), on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type        | Params\n",
      "------------------------------------------\n",
      "0 | bn        | BatchNorm1d | 8     \n",
      "1 | fc1       | Linear      | 20    \n",
      "2 | fc2       | Linear      | 15    \n",
      "3 | train_acc | Accuracy    | 0     \n",
      "------------------------------------------\n",
      "43        Trainable params\n",
      "0         Non-trainable params\n",
      "43        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 19.50it/s, loss=0.937, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 2/2 [00:00<00:00, 16.91it/s, loss=0.937, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "# learning\n",
    "pl.seed_everything(0)\n",
    "net = Net()\n",
    "trainer = pl.Trainer(max_epochs=30)\n",
    "trainer.fit(net, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(4)\n",
    "        self.fc1 = nn.Linear(4, 4)\n",
    "        self.fc2 = nn.Linear(4, 3)\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.val_acc = torchmetrics.Accuracy()\n",
    "        self.test_acc = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.bn(x)\n",
    "        h = self.fc1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.fc2(h)\n",
    "        return h\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, t = batch\n",
    "        y = self(x)\n",
    "        loss = F.cross_entropy(y, t)\n",
    "        # add log\n",
    "        # if on_step==True, the value of each iteration is recorded(default: True)\n",
    "        # if on_epoch==True, the value of each epoch is recorded(default: False)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc', self.train_acc(y, t), on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x ,t = batch\n",
    "        y = self(x)\n",
    "        loss = F.cross_entropy(y, t)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('val_acc', self.val_acc(y, t), on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, t = batch\n",
    "        y = self(x)\n",
    "        loss = F.cross_entropy(y, t)\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('test_acc', self.test_acc(y, t), on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type        | Params\n",
      "------------------------------------------\n",
      "0 | bn        | BatchNorm1d | 8     \n",
      "1 | fc1       | Linear      | 20    \n",
      "2 | fc2       | Linear      | 15    \n",
      "3 | train_acc | Accuracy    | 0     \n",
      "4 | val_acc   | Accuracy    | 0     \n",
      "5 | test_acc  | Accuracy    | 0     \n",
      "------------------------------------------\n",
      "43        Trainable params\n",
      "0         Non-trainable params\n",
      "43        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 3/3 [00:00<00:00, 23.36it/s, loss=0.934, v_num=2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 3/3 [00:00<00:00, 20.94it/s, loss=0.934, v_num=2]\n"
     ]
    }
   ],
   "source": [
    "# learning\n",
    "pl.seed_everything(0)\n",
    "net = Net()\n",
    "trainer = pl.Trainer(max_epochs=30)\n",
    "trainer.fit(net, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at c:\\Users\\nagas\\OneDrive - keio.jp\\programming\\Python_practice\\deeplearning_implementation_introduction\\deeplearning_implementation_introduction\\lightning_logs\\version_2\\checkpoints\\epoch=29-step=60.ckpt\n",
      "Loaded model weights from checkpoint at c:\\Users\\nagas\\OneDrive - keio.jp\\programming\\Python_practice\\deeplearning_implementation_introduction\\deeplearning_implementation_introduction\\lightning_logs\\version_2\\checkpoints\\epoch=29-step=60.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.19it/s] \n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.6000000238418579\n",
      "        test_loss            0.925277054309845\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "results = trainer.test(dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84ad91a4a539be6a2ce1eec2640e282be04f02c4091a066051e3be5a944eca7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
